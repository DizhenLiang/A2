{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dca3785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/student/A2\n"
     ]
    }
   ],
   "source": [
    "#change working directory\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/student/A2/drive-download-20240507T073745Z-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "837b12a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Part b\n",
    "Task 1. Processing Data Stream (45%)\n",
    "Question a\n",
    "\"\"\"\n",
    "from datetime import datetime, timedelta\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "#Residence wifi ip address: 172.16.62.212\n",
    "ipadd = \"10.192.33.112\"\n",
    "\n",
    "client = MongoClient(ipadd, 27017)\n",
    "db = client.fit3182_db\n",
    "collection = db.fit3182_assignment_db\n",
    "\n",
    "#res = collection.find().sort('surface_temperature_celcius', pymongo.DESCENDING).limit(10)\n",
    "res = collection.find().sort('date', pymongo.DESCENDING).limit(1)\n",
    "\n",
    "for d in res:\n",
    "    res = d\n",
    "#     print(d)\n",
    "\n",
    "latest_date = res['date']\n",
    "#string to datetime object\n",
    "# latest_date = datetime.strptime(latest_date, '%Y-%m-%d %H:%M:%S')\n",
    "#string to datetime object\n",
    "latest_date = datetime.strptime(latest_date, '%d/%m/%Y')\n",
    "start_date = latest_date + timedelta(days=1)\n",
    "print(start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f379618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka3 import KafkaProducer\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "hostip = ipadd # change it to your IP\n",
    "\n",
    "def connect_kafka_producer():\n",
    "    producer = None\n",
    "    \n",
    "    try:\n",
    "        producer = KafkaProducer(bootstrap_servers=[f'{hostip}:9092'],api_version=(0,10))\n",
    "    \n",
    "    except Exception as ex:\n",
    "        print(\"Exception while connecting Kafka\")\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return producer \n",
    "    \n",
    "def publish_msg(producer, topic, data):\n",
    "    try:\n",
    "        #print(data)        #send the  value by dumps to JSON object\n",
    "                            #then encode with utf-8 into bytes\n",
    "        value_bytes = json.dumps(data).encode('utf-8')\n",
    "        producer.send(topic, value=value_bytes)\n",
    "        #print(data)\n",
    "        \"\"\"\n",
    "        The flush() method in Kafkaâ€™s producer API is used to ensure that all \n",
    "        previously sent messages have been transmitted to the server and acknowledged \n",
    "        before proceeding. When you call flush(), it blocks the current thread and waits \n",
    "        for the producer to complete the sending of all records\n",
    "        \"\"\"\n",
    "        producer.flush()  \n",
    "    except Exception as ex:\n",
    "        print('Exception from publish_msg func')\n",
    "        print(str(ex))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62ee474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>air_temperature_celcius</th>\n",
       "      <th>relative_humidity</th>\n",
       "      <th>windspeed_knots</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>GHI_w/m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-37.623</td>\n",
       "      <td>149.323</td>\n",
       "      <td>19</td>\n",
       "      <td>56.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.00I</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38.038</td>\n",
       "      <td>142.986</td>\n",
       "      <td>15</td>\n",
       "      <td>50.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.02G</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-37.950</td>\n",
       "      <td>142.366</td>\n",
       "      <td>16</td>\n",
       "      <td>53.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.00G</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38.231</td>\n",
       "      <td>147.172</td>\n",
       "      <td>24</td>\n",
       "      <td>61.6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.00I</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37.903</td>\n",
       "      <td>145.250</td>\n",
       "      <td>24</td>\n",
       "      <td>62.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.00I</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude  longitude  air_temperature_celcius  relative_humidity  \\\n",
       "0   -37.623    149.323                       19               56.8   \n",
       "1   -38.038    142.986                       15               50.7   \n",
       "2   -37.950    142.366                       16               53.6   \n",
       "3   -38.231    147.172                       24               61.6   \n",
       "4   -37.903    145.250                       24               62.3   \n",
       "\n",
       "   windspeed_knots  max_wind_speed precipitation  GHI_w/m2  \n",
       "0              7.9            11.1         0.00I       154  \n",
       "1              9.2            13.0         0.02G       128  \n",
       "2              8.1            15.0         0.00G       133  \n",
       "3              7.7            14.0         0.00I       186  \n",
       "4              7.0            13.0         0.00I       185  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Event Producer 1\n",
    "\"\"\"\n",
    "climate_stream_csv = pd.read_csv(\"./climate_streaming.csv\", sep=',')\n",
    "climate_stream_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57d96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Publishing records..\n",
      "2024-01-05\n",
      "2024-01-06\n",
      "2024-01-07\n",
      "2024-01-08\n",
      "2024-01-09\n",
      "2024-01-10\n",
      "2024-01-11\n",
      "2024-01-12\n",
      "2024-01-13\n",
      "2024-01-14\n",
      "2024-01-15\n",
      "2024-01-16\n",
      "2024-01-17\n",
      "2024-01-18\n",
      "2024-01-19\n",
      "2024-01-20\n",
      "2024-01-21\n",
      "2024-01-22\n",
      "2024-01-23\n",
      "2024-01-24\n",
      "2024-01-25\n",
      "2024-01-26\n",
      "2024-01-27\n",
      "2024-01-28\n",
      "2024-01-29\n",
      "2024-01-30\n",
      "2024-01-31\n",
      "2024-02-01\n",
      "2024-02-02\n",
      "2024-02-03\n",
      "2024-02-04\n",
      "2024-02-05\n",
      "2024-02-06\n",
      "2024-02-07\n",
      "2024-02-08\n",
      "2024-02-09\n",
      "2024-02-10\n",
      "2024-02-11\n",
      "2024-02-12\n",
      "2024-02-13\n",
      "2024-02-14\n",
      "2024-02-15\n",
      "2024-02-16\n",
      "2024-02-17\n",
      "2024-02-18\n",
      "2024-02-19\n",
      "2024-02-20\n",
      "2024-02-21\n",
      "2024-02-22\n",
      "2024-02-23\n",
      "2024-02-24\n",
      "2024-02-25\n",
      "2024-02-26\n",
      "2024-02-27\n",
      "2024-02-28\n",
      "2024-02-29\n",
      "2024-03-01\n",
      "2024-03-02\n",
      "2024-03-03\n",
      "2024-03-04\n",
      "2024-03-05\n",
      "2024-03-06\n",
      "2024-03-07\n",
      "2024-03-08\n",
      "2024-03-09\n",
      "2024-03-10\n",
      "2024-03-11\n",
      "2024-03-12\n",
      "2024-03-13\n",
      "2024-03-14\n",
      "2024-03-15\n",
      "2024-03-16\n",
      "2024-03-17\n",
      "2024-03-18\n",
      "2024-03-19\n",
      "2024-03-20\n",
      "2024-03-21\n",
      "2024-03-22\n",
      "2024-03-23\n",
      "2024-03-24\n",
      "2024-03-25\n",
      "2024-03-26\n",
      "2024-03-27\n",
      "2024-03-28\n",
      "2024-03-29\n",
      "2024-03-30\n",
      "2024-03-31\n",
      "2024-04-01\n",
      "2024-04-02\n",
      "2024-04-03\n",
      "2024-04-04\n",
      "2024-04-05\n",
      "2024-04-06\n",
      "2024-04-07\n",
      "2024-04-08\n",
      "2024-04-09\n",
      "2024-04-10\n",
      "2024-04-11\n",
      "2024-04-12\n",
      "2024-04-13\n",
      "2024-04-14\n",
      "2024-04-15\n",
      "2024-04-16\n",
      "2024-04-17\n",
      "2024-04-18\n",
      "2024-04-19\n",
      "2024-04-20\n",
      "2024-04-21\n",
      "2024-04-22\n",
      "2024-04-23\n",
      "2024-04-24\n",
      "2024-04-25\n",
      "2024-04-26\n",
      "2024-04-27\n",
      "2024-04-28\n",
      "2024-04-29\n",
      "2024-04-30\n",
      "2024-05-01\n",
      "2024-05-02\n",
      "2024-05-03\n",
      "2024-05-04\n",
      "2024-05-05\n",
      "2024-05-06\n",
      "2024-05-07\n",
      "2024-05-08\n",
      "2024-05-09\n",
      "2024-05-10\n",
      "2024-05-11\n",
      "2024-05-12\n",
      "2024-05-13\n",
      "2024-05-14\n",
      "2024-05-15\n",
      "2024-05-16\n",
      "2024-05-17\n",
      "2024-05-18\n",
      "2024-05-19\n",
      "2024-05-20\n",
      "2024-05-21\n",
      "2024-05-22\n",
      "2024-05-23\n",
      "2024-05-24\n",
      "2024-05-25\n",
      "2024-05-26\n",
      "2024-05-27\n",
      "2024-05-28\n",
      "2024-05-29\n",
      "2024-05-30\n",
      "2024-05-31\n",
      "2024-06-01\n",
      "2024-06-02\n",
      "2024-06-03\n",
      "2024-06-04\n",
      "2024-06-05\n",
      "2024-06-06\n",
      "2024-06-07\n",
      "2024-06-08\n",
      "2024-06-09\n",
      "2024-06-10\n",
      "2024-06-11\n",
      "2024-06-12\n",
      "2024-06-13\n",
      "2024-06-14\n",
      "2024-06-15\n",
      "2024-06-16\n",
      "2024-06-17\n",
      "2024-06-18\n",
      "2024-06-19\n",
      "2024-06-20\n",
      "2024-06-21\n",
      "2024-06-22\n",
      "2024-06-23\n",
      "2024-06-24\n",
      "2024-06-25\n",
      "2024-06-26\n",
      "2024-06-27\n",
      "2024-06-28\n",
      "2024-06-29\n",
      "2024-06-30\n",
      "2024-07-01\n",
      "2024-07-02\n",
      "2024-07-03\n",
      "2024-07-04\n",
      "2024-07-05\n",
      "2024-07-06\n",
      "2024-07-07\n",
      "2024-07-08\n",
      "2024-07-09\n",
      "2024-07-10\n",
      "2024-07-11\n",
      "2024-07-12\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Main Function\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    topic = 'Producer1'\n",
    "    print('Publishing records..')\n",
    "    producer01 = connect_kafka_producer()\n",
    "\n",
    "\n",
    "    # Assuming 'climate' is your DataFrame\n",
    "    #print(len(climate.index))\n",
    "    rand_row_indices = list(range(len(climate_stream_csv.index)))\n",
    "    random.shuffle(rand_row_indices)  \n",
    "    #print(len(indices))\n",
    "\n",
    "    for index, climate_row in climate_stream_csv.iterrows():\n",
    "        climate_row = climate_stream_csv.loc[rand_row_indices[index]]\n",
    "\n",
    "        #inner-join\n",
    "    #     if fires_list:\n",
    "            #print(fires_list)\n",
    "\n",
    "        #left-outer join\n",
    "        #print(start_date.strftime('%Y-%m-%d'))\n",
    "        climate_doc = {\n",
    "                                        #string from time with format, \n",
    "                                        #since MongoDB can not store object\n",
    "            #.strftime('%d/%m/%Y')\n",
    "            #convert datetime object to string in format\n",
    "            # laster dumps not work on datetime object but number of string\n",
    "            'latitude': float(climate_row['latitude']),\n",
    "            'longitude': float(climate_row['longitude']),\n",
    "            'air_temperature_celcius': int(climate_row['air_temperature_celcius']),\n",
    "            'relative_humidity': float(climate_row['relative_humidity']),\n",
    "            'windspeed_knots': float(climate_row['windspeed_knots']),\n",
    "            'max_wind_speed': float(climate_row['max_wind_speed']),\n",
    "            #'precipitation ' blank space count as char in csv column\n",
    "            # get to do try except, return None if column not exist\n",
    "            #'precipitation ': str(climate_row.get(['precipitation '])),\n",
    "            #'precipitation': str(climate_row.get(['precipitation'])),\n",
    "            'precipitation': str(climate_row['precipitation']),\n",
    "            'GHI_w/m2': int(climate_row['GHI_w/m2']),\n",
    "            'producer': \"Producer_1\",\n",
    "            'date': start_date.strftime('%Y-%m-%d')\n",
    "\n",
    "        }\n",
    "        #update start date\n",
    "        #print(climate_doc['date'])\n",
    "        #producer publish msg in strictured streaming\n",
    "        # convert the dictionary to JSON-formatted string and encode as UFT-8 by publish_msg\n",
    "        # msg = json.dumps(climate_doc)\n",
    "        #print(climate_doc)\n",
    "        publish_msg(producer01, topic, climate_doc)\n",
    "        start_date += timedelta(days=1)\n",
    "        print(climate_doc['date'])\n",
    "        # change to 1 for debugging\n",
    "        # change to 1 for debugging Task 2: Data Visualisation for debugging\n",
    "        #sleep(1)\n",
    "        sleep(10) # for Assignment_PartB_Streaming_Application.ipynb\n",
    "        #sleep(10) # every 10 seconds send\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Main Function\n",
    "# \"\"\"\n",
    "# if __name__ == '__main__':\n",
    "#     topic = 'Scenaries01'\n",
    "#     print('Publishing records..')\n",
    "#     producer01 = connect_kafka_producer()\n",
    "\n",
    "\n",
    "#     # Assuming 'climate' is your DataFrame\n",
    "#     #print(len(climate.index))\n",
    "#     rand_row_indices = list(range(len(climate.index)))\n",
    "#     random.shuffle(rand_row_indices)  \n",
    "#     #print(len(indices))\n",
    "\n",
    "#     for index, climate_row in climate.iterrows():\n",
    "#         climate_row = climate.loc[rand_row_indices[index]]\n",
    "\n",
    "#         #inner-join\n",
    "#     #     if fires_list:\n",
    "#             #print(fires_list)\n",
    "\n",
    "#         #left-outer join\n",
    "#         #print(start_date.strftime('%Y-%m-%d'))\n",
    "#         climate_doc = {\n",
    "#             'stations': str(climate_row['station']),\n",
    "#                                         #string from time with format, \n",
    "#                                         #since MongoDB can not store object\n",
    "#             #.strftime('%d/%m/%Y')\n",
    "#             #convert datetime object to string in format\n",
    "#             # laster dumps not work on datetime object but number of string\n",
    "#             'date': start_date.strftime('%Y-%m-%d'),\n",
    "#             'air_temperature_celcius': int(climate_row['air_temperature_celcius']),\n",
    "#             'relative_humidity': float(climate_row['relative_humidity']),\n",
    "#             'windspeed_knots': float(climate_row['windspeed_knots']),\n",
    "#             'max_wind_speed': float(climate_row['max_wind_speed']),\n",
    "#             'precipitation': str(climate_row['precipitation']),\n",
    "#             'GHI_w/m2': int(climate_row['GHI_w/m2']),\n",
    "#             'producer': \"Producer_1\"\n",
    "\n",
    "#         }\n",
    "#         #update start date\n",
    "#         #print(climate_doc['date'])\n",
    "#         #producer publish msg in strictured streaming\n",
    "#         # convert the dictionary to JSON-formatted string and encode as UFT-8 by publish_msg\n",
    "#         # msg = json.dumps(climate_doc)\n",
    "#         print(climate_doc)\n",
    "#         publish_msg(producer01, topic, climate_doc)\n",
    "#         start_date += timedelta(days=1)\n",
    "#         # change to 1 for debugging Task 2: Data Visualisation\n",
    "#         sleep(1)\n",
    "#         #sleep(10) # every 10 seconds send\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e5c667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
